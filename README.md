# ğŸš€ Adaptive RAG â€“ Intelligent Retrieval-Augmented Generation System  

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green)
![LangChain](https://img.shields.io/badge/LangChain-AI%20Orchestration-orange)
![Cohere](https://img.shields.io/badge/Cohere-Embeddings-yellow)
![Pinecone](https://img.shields.io/badge/Pinecone-Vector%20DB-blueviolet)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

> A production-grade Retrieval-Augmented Generation (RAG) backend pipeline that adaptively improves its responses through feedback loops and dynamic query transformations.

---

## ğŸ§  Overview  

**Adaptive RAG** is an intelligent document-questioning system built with **LangChain**, **LangGraph**, and **FastAPI**.  
Unlike static RAG systems, this project uses **adaptive retrieval and grading agents** that evaluate whether the retrieved context is relevant â€” and reformulate queries automatically to improve accuracy.  

The pipeline ensures **fewer hallucinations**, **smarter retrieval**, and **better factual consistency** for question-answering tasks.  

---

## ğŸ—ï¸ Architecture  
```
    User Query
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Router Agent (LLM)         â”‚   â† decides "vectorstore" or "web_search"
â”‚ (LangChain prompt)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                    â”‚
    â”‚ vectorstore        â”‚ web_search
    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG Subgraph      â”‚   â”‚ Web Search Agent   â”‚
â”‚ (LangGraph)       â”‚   â”‚ (Tavily search)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                        â”‚
      â–¼                        â–¼
  [Retrieve]               [Return web docs]
  (Pinecone via Cohere)        â”‚
      â”‚                        â”‚
      â–¼                        â””â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ Retrieval Grader  â”‚ <â”€(LLM) evaluates relevance
â”‚ (LLM)             â”‚                 â–¼
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ if no relevant docs      â”‚ Generate Answer â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ (Cohere RAG)    â”‚
      â–¼                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚ Query Rewriter    â”‚ â”€â”€(LLM rewrites)â”€â”€â”˜
â”‚ (LLM)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â””â”€(loop)â”€â”€â–º Retrieve â”€â–º Grade â”€â–º (once good) â–º Generate
                                                
After generation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generation Graders (LLM):                              â”‚
â”‚  - Hallucination Grader (is output grounded in docs?)  â”‚
â”‚  - Answer Grader (does it answer the question?)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
  If useful â†’ Return response (FastAPI â†’ Streamlit)
  Else â†’ Transform query (or retry generation) and loop back
```


---

## âš™ï¸ Tech Stack  

| Component | Technology |
|------------|-------------|
| **Backend** | FastAPI |
| **Orchestration** | LangChain + LangGraph |
| **Embeddings** | Cohere API |
| **Vector Database** | Pinecone |
| **Document Parsing** | LangChain Document Loaders |
| **Language Model** | Cohere Command-R / other LLMs |

---

## âœ¨ Key Features  

âœ… **Adaptive Retrieval Loop** â€“ The system dynamically refines queries when context relevance is low.  
âœ… **Multi-Agent Pipeline** â€“ Separate agents for grading, transforming, and generating responses.  
âœ… **Vector Search** â€“ Uses Pinecone for efficient semantic document retrieval.  
âœ… **Scalable API** â€“ Built with FastAPI for production-level deployment.  
âœ… **Modular Design** â€“ Each component (retriever, grader, generator) is pluggable.  

---

## ğŸ“ Project Structure  
```
Adaptive-RAG/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ api/ # FastAPI endpoints
â”‚ â”œâ”€â”€ agents/ # LangChain-based agents
â”‚ â”œâ”€â”€ core/ # Graph building logic
â”‚ â”œâ”€â”€ utils/ # Config and helper functions
â”‚ â”œâ”€â”€ ingest_blog.py # Script to ingest text into vector DB
â”‚ â”œâ”€â”€ main.py # API entry point
â”‚ â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .env.example # Template for environment variables
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```




## ğŸ”§ Setup & Installation  
```
1ï¸âƒ£ Clone the repository
bash
git clone https://github.com/<your-username>/Adaptive-RAG.git
cd Adaptive-RAG/backend

2ï¸âƒ£ Create a virtual environment

python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)

3ï¸âƒ£ Install dependencies

pip install -r requirements.txt


4ï¸âƒ£ Add environment variables

Create a .env file in the backend folder:

COHERE_API_KEY=your_cohere_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_index_name
5ï¸âƒ£ Ingest documents

Run the ingestion script to embed data into Pinecone:

python ingest_blog.py

6ï¸âƒ£ Run the backend
uvicorn main:app --reload
```